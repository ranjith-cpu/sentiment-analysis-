{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mymod import write_status\n",
    "import re\n",
    "import sys\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_word(word):\n",
    "    # Remove punctuation\n",
    "    word = word.strip('\\'\"?!,.():;')\n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    stop_words = [\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \n",
    "    \"again\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",    \n",
    "    \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"as\", \"at\", \"be\", \"became\", \"because\", \"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"behind\", \"being\", \"beside\", \"besides\", \"between\", \"beyond\", \"both\", \"but\", \"by\",\"can\", \"cannot\", \"cant\", \"could\", \"couldnt\", \"de\", \"describe\", \"do\", \"done\", \"each\", \"eg\", \"either\", \"else\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"find\",\"for\",\"found\", \"four\", \"from\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"i\", \"ie\", \"if\", \"in\", \"indeed\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\",\"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\",\"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"she\", \"should\",\"since\", \"sincere\",\"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"take\",\"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\",\n",
    "    \"this\", \"those\", \"though\", \"through\", \"throughout\",\"im\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"toward\", \"towards\",\n",
    "    \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \n",
    "    \"who\", \"whoever\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\"\n",
    "    ]\n",
    "    if word in stop_words:\n",
    "        word=\"\"\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_word(word):\n",
    "    # Check if word begins with an alphabet\n",
    "    return (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_emojis(review):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :') ,<:o)\n",
    "    review = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\)|\\<:o\\))', ' EMO_POS ', review)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D ,:p\n",
    "    review = re.sub(r'(:\\s?D|:-D|x-?D|X-?D|:p)', ' EMO_POS ', review)\n",
    "    # Love -- <3, :*\n",
    "    review = re.sub(r'(<3|:\\*)', ' EMO_POS ', review)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    review = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', review)\n",
    "    # Confused -- :-S , :s ,:S\n",
    "    review = re.sub(r'(:-?(s|S))', ' EMO_NEG ', review)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:, :'(, :] ,:-|\n",
    "    review = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:|:\\'\\(|:\\]|:-\\|)', ' EMO_NEG ', review)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    review = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(review):\n",
    "    processed_review = []\n",
    "    # Convert to lower case\n",
    "    review = review.lower()\n",
    "    # Replaces URLs with the word URL\n",
    "    review = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', review)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    review = re.sub(r'@[\\S]+', 'USER_MENTION', review)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    review = re.sub(r'#(\\S+)', r' \\1 ', review)\n",
    "    # Remove RT (rereview)\n",
    "    review = re.sub(r'(\\brt\\b|&[\\S])', '', review)\n",
    "    # Replace 2+ dots with space\n",
    "    review = re.sub(r'\\.{2,}', ' ', review)\n",
    "    # Strip space, \" and ' from review\n",
    "    review = review.strip(' \"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    review = handle_emojis(review)\n",
    "    # Replace multiple spaces with a single space\n",
    "    review = re.sub(r'\\s+', ' ', review)\n",
    "    words = review.split()\n",
    "\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word):\n",
    "            if use_stemmer:\n",
    "                word = str(porter_stemmer.stem(word))\n",
    "            processed_review.append(word)\n",
    "\n",
    "    return ' '.join(processed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter preprocessed filemytest-processed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\Sentiment Analysis\\segment.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnum_reviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mt_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mif_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mif_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mif_pos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 8659/100000"
     ]
    }
   ],
   "source": [
    "%run segment.ipynb\n",
    "%run naivebayes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vectort(review):\n",
    "    uni_feature_vector = []\n",
    "    bi_feature_vector = []\n",
    "    words = review.split()\n",
    "    for i in range(len(words) - 1):\n",
    "        word = words[i]\n",
    "        next_word = words[i + 1]\n",
    "        if unigrams.get(word):\n",
    "            uni_feature_vector.append(word)\n",
    "        if USE_BIGRAMS:\n",
    "            if bigrams.get((word, next_word)):\n",
    "                bi_feature_vector.append((word, next_word))\n",
    "    if len(words) >= 1:\n",
    "        if unigrams.get(words[-1]):\n",
    "            uni_feature_vector.append(words[-1])\n",
    "    return uni_feature_vector, bi_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_featurest(review):\n",
    "        features = lil_matrix((1, VOCAB_SIZE))\n",
    "        labels = np.zeros(1)\n",
    "        review_words = review[0]\n",
    "        review_bigrams = review[1]\n",
    "        #print(review_words)\n",
    "        review_words = set(review_words)\n",
    "        review_bigrams = set(review_bigrams)\n",
    "        for word in review_words:\n",
    "                idx = unigrams.get(word)\n",
    "               # print(word)\n",
    "                #print(unigrams)\n",
    "                if idx>=0:\n",
    "                    features[0, idx] += 1\n",
    "        if USE_BIGRAMS:\n",
    "                for bigram in review_bigrams:\n",
    "                    idx = bigrams.get(bigram)\n",
    "                    if idx:\n",
    "                        features[0, UNIGRAM_SIZE + idx] += 1\n",
    "        yield features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = input(\"Enter review :\")\n",
    "use_stemmer = False\n",
    "review = preprocess_review(review)\n",
    "review = get_feature_vectort(review)\n",
    "for test_set_X, _ in extract_featurest(review):\n",
    "        prediction = clf.predict(test_set_X)\n",
    "if prediction[0] == 1:\n",
    "    print(\"positive\")\n",
    "else:\n",
    "    print(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
